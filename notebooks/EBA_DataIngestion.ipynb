{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7bdc2d-0945-4955-aaf9-aef8f553cae7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# EBA Data Ingestion\n",
    "\n",
    "We need to collect data from two main sources for this project:\n",
    " - First is loading the EBA data into the SQL DB\n",
    " - Second is getting the real weather data from NOAA based off Weather stations.   \n",
    "   This is done via FTP using `code/utils/get_weather_data.py` for the relevant time periods.\n",
    " - (Third would be accessing NOAA's forecast DB.)\n",
    "\n",
    " In all cases we will be loading the data into a Postgres Database for easier querying later.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642871af-e81c-4404-9cfd-24715913d5e7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "858272bf-12f1-4178-bf49-601b5a0cddbc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Library Sketch and Table Sketch \n",
    "\n",
    "- 560 MB of weather station data\n",
    "- 2.8GB of Energy data\n",
    "- 5GB of forecast data  (could try to only extract station data)\n",
    "\n",
    "Energy data x 100 ISOs\n",
    "- Demand\n",
    "- Demand Forecast\n",
    "- Net Generation\n",
    "    (by source)\n",
    "- Transfers\n",
    "\n",
    "Weather x 600 stations\n",
    "- Temp\n",
    "- Cloud cover\n",
    "- Precipitation\n",
    "\n",
    "Forecast\n",
    "- Temp (gridded 24 hour forecast) of CONUS.  Probably don't want in DB.\n",
    "- include file ref.\n",
    "- Try to find nearest forecast pixel for all airports.\n",
    "\n",
    "Given we want to think about a whole system forecast, we can live with having a few big tables separated by variable.\n",
    "Use UTC time variables to allow a common index and forecast.\n",
    "\n",
    "Demand Table\n",
    "    id, \n",
    "    datetime\n",
    "    iso1,\n",
    "    iso2,\n",
    "    ...\n",
    "    index on datetime\n",
    "\n",
    "Forecast Table\n",
    "    \"\"\n",
    "\n",
    "Net Generation (*)\n",
    "    \" \" \n",
    "(same for sub-sources)\n",
    "\n",
    "Transfers  (*)\n",
    "   id, \n",
    "   datetime\n",
    "   iso1,\n",
    "   iso2,\n",
    "   amount\n",
    "   index on datetime, \n",
    "\n",
    "AirMeta\n",
    "   id\n",
    "   station_name\n",
    "   lat\n",
    "   long\n",
    "   region\n",
    "   city\n",
    "   state\n",
    "\n",
    "   \n",
    "Temperature\n",
    "   id, \n",
    "   datetime\n",
    "   st1,\n",
    "   st2,\n",
    "   ...\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3de7db-55fc-44c8-b6ce-983c066fde34",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3842681-9405-4fda-a4e8-93e90992ded8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if '/tf' not in sys.path:\n",
    "    sys.path.append('/tf/')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0c3a17c-6975-4fe3-bda5-c6b1daf4c41b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from us_elec.SQL.sqldriver import SQLDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "871d5349-dfdb-40fd-a9f0-d214ac15f9ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqld = SQLDriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63bf3b68-811d-4e42-94c9-d7b13b2041c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sqld.get_data('SELECT * FROM information_schema.tables;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ecac1b-0f49-4474-acb3-c6ceb8af2737",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c009c926-2aaf-453c-a529-56aa28c51a36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bulk EBA data import\n",
    "\n",
    "The EBA data can be downloaded from `https://www.eia.gov/opendata/bulk/EBA.zip`.\n",
    "As of Mar 6, 2023 it's around 2.8 GB, with around 2800 child series, stored in one JSONLines files.\n",
    "\n",
    "That's downloaded to data/EBA/20230302.  \n",
    "For initial quick exploration we you can grep out 'California' and 'Portland' series to \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91fee9-f5f2-4f87-bc73-f9878b0febb2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "197920ca-e557-4624-bdac-e5a84fc3a70a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/us_elec/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b946f39-160c-4295-a79c-fa33d3373c77",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2847 /tf/us_elec/data/EBA/EBA20230302/EBA.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /tf/us_elec/data/EBA/EBA20230302/EBA.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f852a095-f687-42f9-b7d3-b72056e542c1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2893992\r\n",
      "-rw-rw-rw- 1 root root 2760336845 Mar  3 13:13 EBA.txt\r\n",
      "-rw-rw-r-- 1 root root  170876970 Mar  8 01:35 EBA_CA.txt\r\n",
      "-rw-rw-r-- 1 root root   32219742 Mar  8 01:35 EBA_PDX.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l /tf/us_elec/data/EBA/EBA20230302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98da077-eb2f-4f12-a547-80597c3bbe7e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eba_path = '/tf/us_elec/data/EBA/EBA20230302'\n",
    "fname = f'{eba_path}/EBA_PDX.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c67dd54-162f-40e0-a5bd-f656e5733c09",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- grepped out all Portland files and California files for a smaller subset of data to play with while cleaning\n",
    "up the ETL work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0513cec-dfe2-446b-b057-5fbb38f34213",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_eba_txt(fn:str, N:int=None, name_lookup:str=None):\n",
    "    \"\"\"Read in all JSON from Lines file.\n",
    "\n",
    "    Args:\n",
    "    N - maximum number of lines to read in\n",
    "    name_lookup - optional string to search for.  \n",
    "    Return:\n",
    "    List of dicts\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    data = []\n",
    "\n",
    "    #name_reg = re.compile(f'{name_lookup}') if name_lookup else None\n",
    "    with jsonlines.open(fn, 'r') as fh:\n",
    "        for obj in tqdm(fh):\n",
    "            #print(obj.get('series_id'), obj.get('name'))\n",
    "\n",
    "            if name_lookup:\n",
    "                if name_lookup.lower() in obj.get('name').lower():\n",
    "                    print(f\"HIT! {obj['name']}\")\n",
    "                    data.append(obj)\n",
    "                    \n",
    "            else:\n",
    "                data.append(obj)\n",
    "            if N and len(data) >= N:\n",
    "                break\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a21b1-049b-42e9-b38b-32d161f05a01",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- This eats a LOT of ram on it's own for all files.  \n",
    "- Probably best to ETL one at a time.  Even in dict form it's eating around 20GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf0aa0c-49bc-48dc-9a29-569804c9ad89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:01, 27.72it/s]\n"
     ]
    }
   ],
   "source": [
    "all_data = read_eba_txt(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68a524a-15e0-41e3-b721-a47d701f8b1a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eafa65c5-90df-4d0f-94d1-1fbe16ade96f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBA.PGE-ALL.D.H Demand for Portland General Electric Company (PGE), hourly - UTC time\n",
      "66520 [['20230302T22Z', 2957], ['20230302T21Z', 3050]] ['20150722T08Z', 1936]\n",
      "\n",
      "EBA.PGE-ALL.D.HL Demand for Portland General Electric Company (PGE), hourly - local time\n",
      "66520 [['20230302T14-08', 2957], ['20230302T13-08', 3050]] ['20150722T01-07', 1936]\n",
      "\n",
      "EBA.PGE-PACW.ID.H Actual Net Interchange for Portland General Electric Company (PGE) to PacifiCorp West (PACW), hourly - UTC time\n",
      "66250 [['20230301T08Z', 84], ['20230301T07Z', 102]] ['20150721T08Z', -92]\n",
      "\n",
      "EBA.PACW-PGE.ID.H Actual Net Interchange for PacifiCorp West (PACW) to Portland General Electric Company (PGE), hourly - UTC time\n",
      "66959 [['20230301T08Z', -84], ['20230301T07Z', -102]] ['20150701T08Z', 101]\n",
      "\n",
      "EBA.PGE-BPAT.ID.H Actual Net Interchange for Portland General Electric Company (PGE) to Bonneville Power Administration (BPAT), hourly - UTC time\n",
      "66265 [['20230301T08Z', -1638], ['20230301T07Z', -1738]] ['20150721T08Z', -1268]\n",
      "\n",
      "EBA.PGE-BPAT.ID.HL Actual Net Interchange for Portland General Electric Company (PGE) to Bonneville Power Administration (BPAT), hourly - local time\n",
      "66265 [['20230301T00-08', -1638], ['20230228T23-08', -1738]] ['20150721T01-07', -1268]\n",
      "\n",
      "EBA.PACW-PGE.ID.HL Actual Net Interchange for PacifiCorp West (PACW) to Portland General Electric Company (PGE), hourly - local time\n",
      "66959 [['20230301T00-08', -84], ['20230228T23-08', -102]] ['20150701T01-07', 101]\n",
      "\n",
      "EBA.PGE-PACW.ID.HL Actual Net Interchange for Portland General Electric Company (PGE) to PacifiCorp West (PACW), hourly - local time\n",
      "66250 [['20230301T00-08', 84], ['20230228T23-08', 102]] ['20150721T01-07', -92]\n",
      "\n",
      "EBA.BPAT-PGE.ID.HL Actual Net Interchange for Bonneville Power Administration (BPAT) to Portland General Electric Company (PGE), hourly - local time\n",
      "67176 [['20230301T00-08', 1611], ['20230228T23-08', 1713]] ['20150701T01-07', 994]\n",
      "\n",
      "EBA.BPAT-PGE.ID.H Actual Net Interchange for Bonneville Power Administration (BPAT) to Portland General Electric Company (PGE), hourly - UTC time\n",
      "67176 [['20230301T08Z', 1611], ['20230301T07Z', 1713]] ['20150701T08Z', 994]\n",
      "\n",
      "EBA.PGE-ALL.NG.COL.H Net generation from coal for Portland General Electric Company (PGE), hourly - UTC time\n",
      "34656 [['20230302T08Z', 0], ['20230302T07Z', 0]] ['20190319T08Z', 0]\n",
      "\n",
      "EBA.PGE-ALL.NG.WAT.HL Net generation from hydro for Portland General Electric Company (PGE), hourly - local time\n",
      "40705 [['20230302T00-08', 146], ['20230301T23-08', 245]] ['20180701T01-07', 209]\n",
      "\n",
      "EBA.PGE-ALL.NG.NG.HL Net generation from natural gas for Portland General Electric Company (PGE), hourly - local time\n",
      "40704 [['20230302T00-08', 587], ['20230301T23-08', 620]] ['20180701T01-07', 3]\n",
      "\n",
      "EBA.PGE-ALL.NG.WND.H Net generation from wind for Portland General Electric Company (PGE), hourly - UTC time\n",
      "34426 [['20230302T08Z', 0], ['20230302T07Z', 0]] ['20190319T08Z', 0]\n",
      "\n",
      "EBA.PGE-ALL.NG.NG.H Net generation from natural gas for Portland General Electric Company (PGE), hourly - UTC time\n",
      "40704 [['20230302T08Z', 587], ['20230302T07Z', 620]] ['20180701T08Z', 3]\n",
      "\n",
      "EBA.PGE-ALL.NG.WAT.H Net generation from hydro for Portland General Electric Company (PGE), hourly - UTC time\n",
      "40705 [['20230302T08Z', 146], ['20230302T07Z', 245]] ['20180701T08Z', 209]\n",
      "\n",
      "EBA.PGE-ALL.NG.OTH.H Net generation from other for Portland General Electric Company (PGE), hourly - UTC time\n",
      "39426 [['20230302T08Z', 8], ['20230302T07Z', 8]] ['20180701T08Z', 11]\n",
      "\n",
      "EBA.PGE-ALL.NG.COL.HL Net generation from coal for Portland General Electric Company (PGE), hourly - local time\n",
      "34656 [['20230302T00-08', 0], ['20230301T23-08', 0]] ['20190319T01-07', 0]\n",
      "\n",
      "EBA.PGE-ALL.NG.OTH.HL Net generation from other for Portland General Electric Company (PGE), hourly - local time\n",
      "39426 [['20230302T00-08', 8], ['20230301T23-08', 8]] ['20180701T01-07', 11]\n",
      "\n",
      "EBA.PGE-ALL.NG.WND.HL Net generation from wind for Portland General Electric Company (PGE), hourly - local time\n",
      "34426 [['20230302T00-08', 0], ['20230301T23-08', 0]] ['20190319T01-07', 0]\n",
      "\n",
      "EBA.PGE-ALL.TI.H Total interchange for Portland General Electric Company (PGE), hourly - UTC time\n",
      "66286 [['20230302T08Z', -1811], ['20230302T07Z', -1860]] ['20150722T08Z', -861]\n",
      "\n",
      "EBA.PGE-ALL.DF.H Day-ahead demand forecast for Portland General Electric Company (PGE), hourly - UTC time\n",
      "65138 [['20230303T08Z', 2555], ['20230303T07Z', 2704]] ['20150910T08Z', 1918]\n",
      "\n",
      "EBA.PGE-ALL.NG.H Net generation for Portland General Electric Company (PGE), hourly - UTC time\n",
      "66457 [['20230302T08Z', 741], ['20230302T07Z', 873]] ['20150722T08Z', 1075]\n",
      "\n",
      "EBA.PGE-ALL.DF.HL Day-ahead demand forecast for Portland General Electric Company (PGE), hourly - local time\n",
      "65138 [['20230303T00-08', 2555], ['20230302T23-08', 2704]] ['20150910T01-07', 1918]\n",
      "\n",
      "EBA.PGE-ALL.NG.HL Net generation for Portland General Electric Company (PGE), hourly - local time\n",
      "66457 [['20230302T00-08', 741], ['20230301T23-08', 873]] ['20150722T01-07', 1075]\n",
      "\n",
      "EBA.PGE-ALL.TI.HL Total interchange for Portland General Electric Company (PGE), hourly - local time\n",
      "66286 [['20230302T00-08', -1811], ['20230301T23-08', -1860]] ['20150722T01-07', -861]\n",
      "\n",
      "3389908 Portland General Electric Company (PGE) ['EBA.PGE-ALL.DF.H', 'EBA.PGE-ALL.DF.HL']\n",
      "3389992 Portland General Electric Company (PGE) ['EBA.PGE-ALL.D.H', 'EBA.PGE-ALL.D.HL']\n",
      "3390077 Portland General Electric Company (PGE) ['EBA.PGE-ALL.NG.H', 'EBA.PGE-ALL.NG.HL']\n",
      "3390246 Portland General Electric Company (PGE) ['EBA.PGE-ALL.TI.H', 'EBA.PGE-ALL.TI.HL']\n",
      "2122599 Portland General Electric Company (PGE) ['EBA.PGE-BPAT.ID.H', 'EBA.PGE-BPAT.ID.HL', 'EBA.PGE-PACW.ID.H', 'EBA.PGE-PACW.ID.HL']\n",
      "3390162 Portland General Electric Company (PGE) ['EBA.PGE-ALL.NG.COL.H', 'EBA.PGE-ALL.NG.COL.HL', 'EBA.PGE-ALL.NG.NG.H', 'EBA.PGE-ALL.NG.NG.HL', 'EBA.PGE-ALL.NG.OTH.H', 'EBA.PGE-ALL.NG.OTH.HL', 'EBA.PGE-ALL.NG.WAT.H', 'EBA.PGE-ALL.NG.WAT.HL', 'EBA.PGE-ALL.NG.WND.H', 'EBA.PGE-ALL.NG.WND.HL']\n"
     ]
    }
   ],
   "source": [
    "for dat in all_data:\n",
    "    if 'series_id' in dat.keys():\n",
    "        print(dat['series_id'], dat['name'])\n",
    "        print(len(dat['data']), dat['data'][0:2], dat['data'][-1])\n",
    "        print()\n",
    "    else:\n",
    "        print(dat['category_id'], dat['name'], dat['childseries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae26756-6b24-4d60-be5e-07c01169ba6a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "- note that the transfers are not fully aligned for the most recent data?  I suspect some sort of reconciliation procedure\n",
    "clears that up?  Would need to look into that.  Useful for considering trades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec53f2-8716-44fb-8b63-553250652690",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "So we have 4 big categories of data in this thing.  All series are provided with local time and global time variations.\n",
    "\n",
    "- Demand\n",
    "- Demand Forecast\n",
    "- Net Generation\n",
    "- Net Generation (by source) - Much less data\n",
    "- Total Interchange\n",
    "- Interchange with other ISOs\n",
    "\n",
    "- Around 8 years of data for demand/net generation.\n",
    "- Around 5 years for generation by source data.\n",
    "- Hourly resolution \n",
    "- Around 100 ISOs  (2850 series, 30 series per ISO, but variable interchanges).\n",
    "- 60k data points per series at hourly resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df09c9-270d-4b8f-ba68-fb5bb8431d74",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Proposed SQL Table Structure - EBA\n",
    "\n",
    "- Our initial project is focused on the demand forecasting piece.  Let's just focus on the bulk attributes for now, and return later if need be for\n",
    " breakdowns by generation type\n",
    "\n",
    "### Options:\n",
    "1) 1 table per series (hard to look up) - Reject.\n",
    "\n",
    "2) 1 table per type (100 ISOs as columns).\n",
    "    - Demand (Time, PDX, BPA, CAISO, ...)\n",
    "    - Forecast (Time, PDX, BPA, CAISO, ...)\n",
    "    - Net Generation (Time, PDX, BPA, CAISO,...)\n",
    "    - Interchange(Time, P1, P2, Amount)\n",
    "\n",
    "3) 1 major table per ISO (around 30 sub-series)\n",
    "   -  PGE (Time, Demand, Forecast, Net Generation, COL, HYD, ..., PGE-BPA, PGE-PACW)\n",
    "   -  BPA (Time, Demand, Forecast, Net Generation, COL, HYD, ..., BPA-PGE, PGE-PACW)\n",
    "\n",
    "Leaning toward approach 3.  Better encapsulates system process.  Allows local time and UTC time\n",
    "Also leaning towards only including UTC time variations.\n",
    "\n",
    "- Need all series names (types of data)\n",
    "- Need all ISOs and transferes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe4a9822-01d3-48be-9ec0-e6f02d61a576",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea9e5f45-a223-490f-9ecb-c267974eb522",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['series_id',\n",
       " 'name',\n",
       " 'units',\n",
       " 'f',\n",
       " 'description',\n",
       " 'start',\n",
       " 'end',\n",
       " 'last_updated',\n",
       " 'geoset_id',\n",
       " 'data']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aee0a7-1911-4837-b447-8338dd060e42",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Getting Metadata\n",
    "\n",
    "(Increasingly getting feeling that Mongo is the way to really handle this data)\n",
    "\n",
    "## EBA\n",
    "\n",
    "Want:\n",
    "- list of ISOs\n",
    "  -- can get by parsing the EBA.txt dump for stuff with child series.  That's the metadata about relations between series\n",
    "\n",
    "## Airports\n",
    "\n",
    "I think the `merge_air_df` is probably already close to what we want: mapping from id to name/region.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "name": "EBA_DataIngestion.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
